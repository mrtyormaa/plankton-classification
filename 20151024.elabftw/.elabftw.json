[{"type":"experiments","title":"Add Feature: Harallic Textures ~ 0.2% increase in efficiency","body":"<p><span style=\"font-size: 14pt;\"><strong>Goal : Add feature : Harallic textures ~0.2% increase in efficiency.<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Procedure :<\/strong><\/span><\/p>\r\n<p>An <strong>image texture<\/strong> is a set of metrics calculated in image processing designed to quantify the perceived texture of an image. Image texture gives us information about the spatial arrangement of color or intensities in an image or selected region of an image.<\/p>\r\n<p>Image textures can be artificially created or found in natural scenes captured in an image. Image textures are one way that can be used to help in segmentation&nbsp;or classification of images. To analyze an image texture in computer graphics, there are two ways to approach the issue: Structured Approach and Statistical Approach.<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Results :<\/strong><\/span><\/p>\r\n<p>The tradeoff was not worth it. I had to add 52 columns to the feature matrix. But this resulted only in a slight increase of efficiency by 0.2%. Hence, this feature will be excluded fromt the final application.<\/p>","date":"20151024","files":[]},{"type":"experiments","title":"Find a new feature by trial and error","body":"<p><span style=\"font-size: 14pt;\"><strong>Goal : To find a new feature which is suitable for the application by trial and error.<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Procedure :<\/strong><\/span><\/p>\r\n<p>We have a lot of information being extracted from the libraries 'scikit-images and mahotas'<\/p>\r\n<p>At this point, I have observed that it is very difficult to get an increase in the efficiency. Getting 40% efficiency is very easy. It can be easily done by the rescaled pixels and the geomatric properties of the images.<\/p>\r\n<p>But moving forward, getting each level of efficiency is getting harder. I don't have expertise in image recognition. Hence, one of the strategies at this point is Brute force Trial and Error.<\/p>\r\n<p>This strategy can be applied as I have already reduced the test data set to 4000 instead of initial 30,000 images.&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Results :<\/strong><\/span><\/p>\r\n<p>&nbsp;This trial and error method took 5 hours in all. But I was able to identify three more crucial features<\/p>\r\n<p>1. Zernike Moments<\/p>\r\n<p>2. Harallic Features<\/p>\r\n<p>3.&nbsp;Parameter Free Threshold Adjacency Statistics<\/p>","date":"20151022","files":null},{"type":"experiments","title":"Add feature: Linear Binary Pattern : 49%","body":"<p><span style=\"font-size: 14pt;\"><strong>Goal :<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Procedure :<\/strong><\/span><\/p>\r\n<p>&nbsp;<strong>Local binary patterns<\/strong> (LBP) is a type of feature used for classification in computer vision. LBP is the particular case of the Texture Spectrum model.&nbsp;<\/p>\r\n<p>The LBP feature vector, in its simplest form, is created in the following manner:<\/p>\r\n<ul>\r\n<li>Divide the examined window into cells (e.g. 16x16 pixels for each cell).<\/li>\r\n<li>For each pixel in a cell, compare the pixel to each of its 8 neighbors (on its left-top, left-middle, left-bottom, right-top, etc.). Follow the pixels along a circle, i.e. clockwise or counter-clockwise.<\/li>\r\n<li>Where the center pixel's value is greater than the neighbor's value, write \"1\". Otherwise, write \"0\". This gives an 8-digit binary number (which is usually converted to decimal for convenience).<\/li>\r\n<li>Compute the histogram, over the cell, of the frequency of each \"number\" occurring (i.e., each combination of which pixels are smaller and which are greater than the center).<\/li>\r\n<li>Optionally normalize the histogram.<\/li>\r\n<li>Concatenate (normalized) histograms of all cells. This gives the feature vector for the window<\/li>\r\n<\/ul>\r\n<p>Hence, this might be a very successful feature for further classification.<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Results :<\/strong><\/span><\/p>\r\n<p>&nbsp;This was a huge success. I got an improvement of 1% by addition of one metric. The final efficiency of the system at present lies at 49%.<\/p>","date":"20151021","files":null},{"type":"experiments","title":"Add Features: All Measure Properties - 46%","body":"<p><span style=\"font-size: 14pt;\"><strong>Goal :&nbsp;Add Features: All Measure Properties<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Procedure :<\/strong><\/span><\/p>\r\n<p>&nbsp;When we divide the image based on the region while pre-processing the image, we can get a lot of good features from it. The features are as follows:<\/p>\r\n<p>i. ratio<\/p>\r\n<p>ii. minor_axis_length<\/p>\r\n<p>iii. major_axis_length<\/p>\r\n<p>iv. area<\/p>\r\n<p>v. convex area<\/p>\r\n<p>vi. eccentricity<\/p>\r\n<p>vii. equivalent_diameter<\/p>\r\n<p>viii. euler number<\/p>\r\n<p>ix. extent<\/p>\r\n<p>x. filled area<\/p>\r\n<p>xi. orientation<\/p>\r\n<p>xii. perimeter<\/p>\r\n<p>xiii. solidity&nbsp;<\/p>\r\n<p>xiv. centriod<\/p>\r\n<p>As we can see from the features, these are all geomatrical properties of the image. We have had a lot of success from classifying the images just from the width to height ratio before. These all additions should improve the performance by a lot. This makes a lot of sense as the images vary a lto and can be easily distinguished by their geomatrical shapes. A few of the classes have very similar shapes and can't be distinguished. We can identify these classes later and try to address them by some other method.<\/p>\r\n<p>&nbsp;<\/p>\r\n<p>Steps:<\/p>\r\n<p>1. Calculated all the features by using the Measure Module from the scikit-image library.<\/p>\r\n<p>2. Added the features to the feature matrix.<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Results :<\/strong><\/span><\/p>\r\n<p>The efficiency increased from 43% to 46%&nbsp;<\/p>","date":"20151020","files":null},{"type":"experiments","title":"Add Feature: Hu Invariant Moments - 48%","body":"<p><span style=\"font-size: 14pt;\"><strong>Goal :&nbsp;Add Feature: Hu Invariant Moments - 48%<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Procedure :<\/strong><\/span><\/p>\r\n<p>&nbsp;The non-orthogonal centralised moments are translation invariant and can be normalised with respect to changes in scale. However, to enable invariance to rotation they require reformulation. Hu described two different methods for producing rotation invariant moments. The first used a method called principal axes, however it was noted that this method can break down when images do not have unique principal axes. Such images are described as being rotationally symmetric. The second method Hu described is the method of absolute moment invariants and is discussed here. Hu derived these expressions from algebraic invariants applied to the moment generating function under a rotation transformation. They consist of groups of nonlinear centralised moment expressions. The result is a set of absolute orthogonal (i.e. rotation) moment invariants, which can be used for scale, position, and rotation invariant pattern identification. These were used in a simple pattern recognition experiment to successfully identify various typed characters.<\/p>\r\n<p>We can use this to see if the performance of our application improves.&nbsp;<\/p>\r\n<p>This is a trial and error experiment. I say this to be trial and error because we already have implemented a lot of features which can be derived from the geomatrical properties of the images. This feature too heavily relies on the geomatrical properties. Hence the results might not improve a lot.<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Results :<\/strong><\/span><\/p>\r\n<p>&nbsp;I saw an increase of performance by 2%. This is a good trade of for 7 features. Hence, I am keeping Hu moments for th final analysis.<\/p>","date":"20151020","files":null},{"type":"experiments","title":"Increase the Number of training data : Artificial Increase of data by various strategies","body":"<p><span style=\"font-size: 14pt;\"><strong>Goal :To increase the number of images in trianing data.<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Procedure :<\/strong><\/span><\/p>\r\n<p>&nbsp;Planktons are sea creatures without a fixed orientation. What I mean to say is, we can identify the images of humans or dogs etc.. by their orientation. They can be straight or upside down or roatated at some angle. But planktons are not identified by that.<\/p>\r\n<p>So, a easy strategy to artificially boost the trainign data is to rotate the images by a random value. This will double our set of training data. This also might lead to significant increase in performance.<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Results :<\/strong><\/span><\/p>\r\n<p>&nbsp;This experiment was a failure. I could not see a significant increase in the performance. The performance increased from 48% to 48.2%. But the time taken to train the system increased significantly almost double the inital time.<\/p>\r\n<p>Hence, the changes will be rejected. This strategy is dropped.<\/p>","date":"20151020","files":null},{"type":"experiments","title":"Add Feature : Width to Height Ratio","body":"<p><span style=\"font-size: 14pt;\"><strong>Goal : Add the feature : Width to height ratio<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Procedure :<\/strong><\/span><\/p>\r\n<p>After vewing the mages, I came to the conclusion that, a lot of the images can be can be easily classified to their correct classification based on their wdth to height ratio. A lot of images have specific shapes and they are in constant proportion in all images.<\/p>\r\n<p>1. Pre-process the image.<\/p>\r\n<p>2. Get the width to height ratio using the Measure Module from the 'scikit-image' library.<\/p>\r\n<p>3. Add to the feature matrix.<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Results :<\/strong><\/span><\/p>\r\n<p>I got 43% accuracy by doing so.<\/p>\r\n<p>This was the first working model of the application with a proper feature and significant results.<\/p>\r\n<p>Although, this is a success, I am marking this experiment as to be redone. The measure module provides a lot of features which can be readily used for this project. The experiment has to continue to include some or all of the other properties and see the trade-off between performance vs speed.<\/p>","date":"20151019","files":null},{"type":"experiments","title":"Create test data","body":"<p><span style=\"font-size: 14pt;\"><strong>Goal : To a create test data (smaller).<\/strong><\/span><\/p>\r\n<p>&nbsp;The training data is large. It takes a lot of time to run the code. It is not advisable to go over the whole training data for smoke tests. It will be better to work with a smaller subset of the training data to perform initial tests before finally running the system.<\/p>\r\n<p>&nbsp;It is improtant to include all the classes in the test data. This will ensure the application will perform properly when it is using the actual training data.<\/p>\r\n<p>All the classes should have at least 10 images and less than 100 images, instead of hundreds&nbsp;or thousands of images.<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Procedure :&nbsp;<\/strong><\/span><\/p>\r\n<p>One of the observations about all the test files was the name of the files. They all had numbers as their filenames and ranged from 100 - 999999. And every folder a mix of different length of filenames.<\/p>\r\n<p>1. Make a copy of the training data.<\/p>\r\n<p>2. Delete all files&nbsp;which have 5 or more characters in their filename.<\/p>\r\n<p>&nbsp;<\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Results :<\/strong><\/span><\/p>\r\n<p>1. Reduced number of images for testing from 30460 to 4652.<\/p>\r\n<p>2. Runtime for smoke-test was reduced to under ~2mins as compared ~5-7 mins.<\/p>","date":"20151018","files":null},{"type":"experiments","title":"Rescale image and add the pixel as features : Efficiency - 38%","body":"<p><span style=\"font-size: 14pt;\"><strong>Goal : To rescale image to 25x25 and add all 625 pixels as features.<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Procedure :<\/strong><\/span><\/p>\r\n<p>&nbsp;The images vary a lot in their sizes. Some are really big ie.e 200x300. If we try to add all the pixels as our features, we will end up with more features than we have test data to work with. This strategy won't work.<\/p>\r\n<p>Hence, the approach is to rescale the image after pre-processing it. The rescale value is set to be 25x25. This generates 625 pixels per image. We have fair number of images to work with.<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Results :<\/strong><\/span><\/p>\r\n<p>This strategy was executed successfully. The classification rate was at a very high of 38%.&nbsp;<\/p>","date":"20151018","files":null},{"type":"experiments","title":"Add a new feature - Failure","body":"<p><span style=\"font-size: 14pt;\"><strong>Goal : To add a (random) feature to the application.<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Procedure :&nbsp;<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>1. Created a new vector of features.<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>2. Added the feature eccentricity to it.<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>3. Added to the Random Forest.<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>4. Tested results<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Results :<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>1. The application&nbsp;executed successfully.<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>2. This experiment was a failure as&nbsp;the runtime of the application increased significantly.<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>3. Came to the conclusion that this is not the right approach. Instead of creating a new vector, it is better to append to the existing feature vector.<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>","date":"20151018","files":null},{"type":"experiments","title":"Add a new feature - Success","body":"<p><span style=\"font-size: 14pt;\"><strong>Goal : To add a (random) new feature to the application<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Procedure :<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>1. Used 'scikit-image' library to extract &nbsp;a new feature from the image.<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>2. Added the new feature to the existing feature matrix.<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>3. Passed the feature list.<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Results :<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 18.6667px;\"><strong>1. Successfully added a new project.<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 18.6667px;\"><strong>2. The runtime of the application was reasonable with ~3mins.<\/strong><\/span>&nbsp;&nbsp;<\/p>","date":"20151018","files":null},{"type":"experiments","title":"Initial Set-up","body":"<p><span style=\"font-size: 14pt;\"><strong>Goal : To set up&nbsp;a working system to experiment with. - Python<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Procedure : Follow the steps in Kaggle Plankton Tutorial.<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Results :<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>1. Successfully set-up the initial system.<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>2. Got the understanding of the whole system, how it works and what changes needs to be done.<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>3. Identified the key libraires to use.<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>i. numpy<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>ii. mahotas<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>iii. OpenCV<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>iv. scikit-image<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>3. The efficiency of the system is measures by a efficient library called 'KFLogs'<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p>&nbsp;<\/p>","date":"20151017","files":null},{"type":"experiments","title":"Understand Image Feature Extraction","body":"<p><span style=\"font-size: 14pt;\"><strong>Goal :&nbsp;Understand the feature extraction process for images.<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Procedure :&nbsp;<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>1. Went through the links suggested by the staff.<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>2. Studied the winning solutions for the Kaggle Challenge.<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>3. Looked through a lot of images to understand how they differ. <\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>4. Tried to get an understanding of how the different classes differ from each other visually and how can I capture that programatically.&nbsp;<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Results :<\/strong><\/span><\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>1. Got a good grasp on&nbsp;features of images.<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>","date":"20151017","files":null},{"type":"experiments","title":"Initial Project Setup: Using java","body":"<p><span style=\"font-size: 14pt;\"><strong>Goal :&nbsp;Initial Project Setup: Using java<\/strong><\/span><\/p>\r\n<p>&nbsp;<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Procedure :<\/strong><\/span><\/p>\r\n<p>&nbsp;Started the project using Java. Identified ImgeJ and Colt as to of the main libraries for this project.<\/p>\r\n<p><span style=\"font-size: 14pt;\"><strong>Results :<\/strong><\/span><\/p>\r\n<p>&nbsp;Realized that it is extremely slow.<\/p>\r\n<p>The image identification libraries are not very efficient.<\/p>\r\n<p>I cannot get all the features I am planning to get using this library.<\/p>","date":"20151015","files":null}]